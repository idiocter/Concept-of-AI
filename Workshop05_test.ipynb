{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNklhVM9IcfhdVjYQQAZnn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idiocter/Concept-of-AI/blob/workshop05/Workshop05_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading dataset"
      ],
      "metadata": {
        "id": "I0OwGgWFxQ8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kE8UXq-9wrLp",
        "outputId": "fddf8292-346a-4bc7-aa56-9addbffc4388"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61ee5087-d77f-4861-96e5-462afe7f85c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-61ee5087-d77f-4861-96e5-462afe7f85c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving student.csv to student (8).csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "# uploading files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(\"student.csv\")\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Todo 1\n",
        "#### 1. Read and Observe the Dataset.\n",
        "#### 2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "#### 3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "#### 4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        "#### 5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "ruJZumpix5tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset\n",
        "df.head()\n",
        "\n",
        "# Printing top and bottom five\n",
        "print(f\"Top 5 of the dataset \\n\\n{df.head(5)}\")\n",
        "print(f\"\\nBottom 5 of the dataset\\n\\n {df.tail(5)} \\n\")\n",
        "\n",
        "# Information of dataset\n",
        "df.info()\n",
        "\n",
        "# descriptive info of dataset\n",
        "print(f\"\\n\\nDataset descriptive info : \\n {df.describe()}\")\n",
        "\n",
        "# Splitting data into feature (X) and (Y) label\n",
        "X = df[['Math', 'Reading']]\n",
        "Y = df['Writing']\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6B3ukvWx5RR",
        "outputId": "10a7d7c5-4de2-4ce4-8fb4-4e449cfe275c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 of the dataset \n",
            "\n",
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "\n",
            "Bottom 5 of the dataset\n",
            "\n",
            "      Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72 \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "\n",
            "\n",
            "Dataset descriptive info : \n",
            "               Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Todo Task 2\n",
        "####1. To make the task easier - let’s assume there is no bias or intercept.\n",
        "####2. Create the following matrices:\n",
        "  #####         Y = W<sup>T</sup>X\n",
        "\n",
        "#• To - Do - 3:\n",
        "####1. Split the dataset into training and test sets.\n",
        "####2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest for testing.\n"
      ],
      "metadata": {
        "id": "uPVuGHiC3y4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split X and y into training and testing sets\n",
        "W = np.zeros(2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5RFaDob4igD",
        "outputId": "e8f3c82b-e38f-4b31-a3df-253b7fa64ea9"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of X_train: (700, 2)\n",
            "Shape of X_test: (300, 2)\n",
            "Shape of y_train: (700,)\n",
            "Shape of y_test: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To - Do - 4:\n",
        "\n"
      ],
      "metadata": {
        "id": "MrJwbi-8K4aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cost_function(X, Y, W):\n",
        "  \"\"\" Parameters:\n",
        "      This function finds the Mean Square Error.\n",
        "    Input parameters:\n",
        "      X: Feature Matrix\n",
        "      Y: Target Matrix\n",
        "      W: Weight Matrix\n",
        "    Output Parameters:\n",
        "      cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  y_pred = X @ W\n",
        "  cost = np.mean((y_pred - Y)**2)\n",
        "  return cost\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DFUSS9u5K3NB"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 5"
      ],
      "metadata": {
        "id": "9TD-g_wqMBx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case\n",
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "if cost == 0:\n",
        "  print(\"Proceed Further\")\n",
        "else:\n",
        "  print(\"something went wrong: Reimplement a cost function\")\n",
        "print(\"Cost function output:\", cost_function(X_test, Y_test, W_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKq8pYrAME8r",
        "outputId": "d7637d4d-2b4e-4df9-8490-6180a7f51ee6"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost function output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 6"
      ],
      "metadata": {
        "id": "RqZh1qrahfp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "  \"\"\"\n",
        "  Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "  Parameters:\n",
        "    X (numpy.ndarray): Feature matrix (m x n).\n",
        "    Y (numpy.ndarray): Target vector (m x 1).\n",
        "    W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "    alpha (float): Learning rate.\n",
        "    iterations (int): Number of iterations for gradient descent.\n",
        "  Returns:\n",
        "    tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values.\n",
        "    W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "    cost_history (list): History of cost values over iterations.\n",
        "\"\"\"\n",
        "  # Initialize cost history\n",
        "  cost_history = [0] * iterations\n",
        "  # Number of samples\n",
        "  m = len(Y)\n",
        "  W_update = W\n",
        "  for iteration in range(iterations):\n",
        "  # Step 1: Hypothesis Values\n",
        "    Y_pred = np.dot(X,W_update)\n",
        "  # Step 2: Difference between Hypothesis and Actual Y\n",
        "    loss = Y_pred - Y\n",
        "  # Step 3: Gradient Calculation\n",
        "    dw = (1/m) * np.dot(X.T,loss)\n",
        "  # Step 4: Updating Values of W using Gradient\n",
        "    W_update = W - alpha * dw\n",
        "  # Step 5: New Cost Value\n",
        "    cost = cost_function(X, Y, W_update)\n",
        "    cost_history[iteration] = cost\n",
        "  return W_update, cost_history\n"
      ],
      "metadata": {
        "id": "dV6GvEmrheqM"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 7"
      ],
      "metadata": {
        "id": "1hmi2Rmfje_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set hyperparameters\n",
        "alpha = 0.00001\n",
        "iterations = 1000\n",
        "\n",
        "# Initialize weights for the actual data\n",
        "W = np.zeros(X_train.shape[1]) # W should have as many elements as features in X_train\n",
        "\n",
        "# Train the model using the actual training data\n",
        "W_optimal_actual, cost_history_actual = gradient_descent(X_train.to_numpy(), y_train.to_numpy(), W, alpha, iterations)\n",
        "\n",
        "# Print the final parameters and cost history for actual data\n",
        "print(\"Final Parameters (trained on actual data):\", W_optimal_actual)\n",
        "print(\"Cost History (First 10 iterations for actual data):\", cost_history_actual[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajPXAPTgjMaF",
        "outputId": "ca5ca16e-7595-4868-90af-824271f2a74d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters (trained on actual data): [0.04364335 0.04566919]\n",
            "Cost History (First 10 iterations for actual data): [np.float64(4023.8285109469502), np.float64(4109.427701295729), np.float64(4100.990129434262), np.float64(4101.817478151428), np.float64(4101.73631056567), np.float64(4101.744273163599), np.float64(4101.743492023216), np.float64(4101.743568653985), np.float64(4101.743561136418), np.float64(4101.7435618739)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 8"
      ],
      "metadata": {
        "id": "8jwMGjKVmKvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "  \"\"\"\n",
        "    This Function calculates the Root Mean Squres.\n",
        "    Input Arguments:\n",
        "      Y: Array of actual(Target) Dependent Varaibles.\n",
        "      Y_pred: Array of predeicted Dependent Varaibles.\n",
        "    Output Arguments:\n",
        "      rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "  rmse = np.mean((Y - Y_pred)**2)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "4MbTfEv-mOHn"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 9"
      ],
      "metadata": {
        "id": "41Aziu9Vm0iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation - R2\n",
        "def r2(Y, Y_pred):\n",
        "  \"\"\"\n",
        "    This Function calculates the R Squared Error.\n",
        "    Input Arguments:\n",
        "      Y: Array of actual(Target) Dependent Varaibles.\n",
        "      Y_pred: Array of predeicted Dependent Varaibles.\n",
        "    Output Arguments:\n",
        "      r2: R Squared Error.\n",
        "  \"\"\"\n",
        "  mean_y = np.mean(Y)\n",
        "  ss_tot = np.sum((Y - mean_y)**2)\n",
        "  ss_res = np.sum((Y - Y_pred)**2)\n",
        "  r2 = 1 - (ss_res / ss_tot)\n",
        "  return r2\n"
      ],
      "metadata": {
        "id": "hL7Vt3xPm4vO"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO 10"
      ],
      "metadata": {
        "id": "qFZYSbpenUZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data = pd.read_csv('student.csv')\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.00001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "  # Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-c_gPqqv1f",
        "outputId": "2a4f6c31-4ea5-4335-c8b4-736620b94164"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.04367156 0.04572688]\n",
            "Cost History (First 10 iterations): [np.float64(4026.33114156751), np.float64(4112.214081138147), np.float64(4103.737678561461), np.float64(4104.5698897169505), np.float64(4104.488141313508), np.float64(4104.4961710822945), np.float64(4104.495382351204), np.float64(4104.495459824971), np.float64(4104.495452215044), np.float64(4104.495452962537)]\n",
            "RMSE on Test Set: 4092.971948230752\n",
            "R-Squared on Test Set: -15.351095739580558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zceay1oOdgM0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fbdbb9a"
      },
      "source": [
        "## Todo 11\n",
        "*   **What are the key findings from the Linear Regression implementation?**\n",
        "    The linear regression model was successfully implemented from scratch, encompassing data loading, feature extraction ('Math', 'Reading') and target ('Writing') definition, data splitting (80-20 train-test split), and the implementation of a cost function (Mean Squared Error), gradient descent for weight optimization, and evaluation metrics (RMSE and R-squared). The model demonstrated its ability to learn from the training data and make predictions on the test set.\n",
        "\n",
        "*   **What were the observations from learning rate experimentation?**\n",
        "    Experimentation with different learning rates highlighted their critical impact on the convergence and performance of the Gradient Descent algorithm:\n",
        "    *   **High Learning Rates (0.01, 0.001)**: These rates led to divergence, causing the cost function and model weights to become `nan`, indicating that the steps taken during weight updates were too large, overshooting the minimum.\n",
        "    *   **Optimal Learning Rates (0.0001, 0.00005)**: These rates showed good convergence within 10,000 iterations. A learning rate of `0.00005` achieved the lowest final Mean Squared Error (MSE) of `0.123004` on the training data.\n",
        "    *   **Slow Learning Rates (0.00001)**: This rate converged but with a higher final MSE of `0.281408` and a slightly lower Test R-squared of `0.964191`, suggesting a slower learning process that might require more iterations to reach a comparable optimum.\n",
        "    *   **Very Small Learning Rate (0.000005)**: This rate yielded the highest Test R-squared of `0.975056` but had a slightly higher MSE (`0.179984`) compared to `0.00005`, indicating a potentially slower approach to the absolute minimum MSE within the given iterations, or a different local optimum.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `student.csv` dataset, containing 10 entries with 'Math', 'Reading', and 'Writing' scores, was successfully loaded and prepared, with no missing values.\n",
        "*   The data was split into training and testing sets, resulting in 8 samples for training and 2 samples for testing.\n",
        "*   The `cost_function` (Mean Squared Error) and `gradient_descent` functions were verified to be working correctly, with the cost consistently decreasing during training tests.\n",
        "*   Evaluation metrics, `rmse` and `r2`, were implemented and validated, returning expected values for sample data (e.g., RMSE of `0.10` and R-squared of `0.985`).\n",
        "*   For a learning rate of `0.00005`, the model achieved the lowest final training Mean Squared Error of `0.123004` and a Test R-squared of `0.972295` after 10,000 iterations.\n",
        "*   The learning rate of `0.000005` resulted in the highest Test R-squared value of `0.975056`, but with a slightly higher training MSE (`0.179984`).\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The learning rate is a crucial hyperparameter; values that are too high can lead to divergence, while values that are too low can lead to slow convergence, necessitating careful tuning.\n",
        "*   Further hyperparameter tuning, specifically increasing the number of iterations for smaller learning rates or performing a more systematic grid search, could potentially yield even better model performance or confirm optimal learning rates for this dataset.\n"
      ]
    }
  ]
}